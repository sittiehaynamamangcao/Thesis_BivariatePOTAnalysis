---
title: "Bivariate POT Analysis"
author: "S M"
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    df_print: paged
---

```{r message=FALSE, warning=FALSE, include=FALSE}
library(readxl)

# Road Accident Data
data_road <- read.csv("C:/Users/Yna/Downloads/4th YR - 2nd Sem/Bivariate POT Reference/THESIS FINAL DATA/monthly_road_accident_tasmania.csv")

# Rainfall Data
precipitation_data <- read.csv("C:/Users/Yna/Downloads/4th YR - 2nd Sem/Bivariate POT Reference/THESIS FINAL DATA/tasmania_precipitation_table.csv")
```

```{r message=FALSE, warning=FALSE}
# --- Load Required Packages ---
#install.packages(c("POT", "ismev", "copula", "evd", "lubridate", "ggplot2", "dplyr"))
library(POT)
library(ismev)
library(copula)
library(evd)
library(lubridate)
library(ggplot2)
library(dplyr)

# --- Load and Merge Data ---
accidents <- data_road
precip <- precipitation_data
```

# Exploratory Data Analysis

```{r data_preparation, message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)
library(scales)

# Assuming accidents and precip dataframes are already available
# Merge by Year and Month
df <- merge(accidents, precip, by = c("Year", "Month"))

# Rename columns for clarity
names(df)[names(df) == "Count"] <- "Accidents"
names(df)[names(df) == "Average"] <- "Rainfall"

# Calculate average per month (across all years)
monthly_avg <- df %>%
  group_by(Month) %>%
  summarize(
    Avg_Rainfall = mean(Rainfall, na.rm = TRUE),
    Avg_Accidents = mean(Accidents, na.rm = TRUE)
  ) %>%
  # Round averages for display
  mutate(
    Avg_Rainfall_rounded = round(Avg_Rainfall, 1),
    Avg_Accidents_rounded = round(Avg_Accidents, 2)
  )

# Convert to long format for grouped bar chart
monthly_avg_long <- monthly_avg %>%
  pivot_longer(
    cols = c(Avg_Rainfall, Avg_Accidents),
    names_to = "Metric",
    values_to = "Value"
  ) %>%
  # Add rounded values for labels
  mutate(
    Label = ifelse(
      Metric == "Avg_Rainfall", 
      as.character(round(Value, 1)),
      as.character(round(Value, 2))
    )
  )

# Create a vector with month names in order
month_names <- month.abb
monthly_avg_long$Month_Name <- factor(month_names[monthly_avg_long$Month], levels = month_names)

# For rainfall
rainfall_plot <- ggplot(monthly_avg, aes(x = factor(month.abb[Month], levels = month.abb), y = Avg_Rainfall)) +
  geom_bar(stat = "identity", fill = "lightblue", alpha = 0.7) +
  geom_text(aes(label = Avg_Rainfall_rounded), vjust = -0.5, size = 3.5) +
  labs(
    title = "Average Monthly Rainfall (mm) in Tasmania",
    x = "Month",
    y = "Average Rainfall (mm)"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "right"
  ) +
  # Add a legend
  guides(fill = guide_legend(title = "Metric")) +
  scale_fill_manual(values = "navy", name = "Metric", labels = "Rainfall (mm)")

# For accidents  
accidents_plot <- ggplot(monthly_avg, aes(x = factor(month.abb[Month], levels = month.abb), y = Avg_Accidents)) +
  geom_bar(stat = "identity", fill = "lightblue", alpha = 0.7) +
  geom_text(aes(label = Avg_Accidents_rounded), vjust = -0.5, size = 3.5) +
  labs(
    title = "Average Monthly Fatal Road Accidents in Tasmania",
    x = "Month",
    y = "Average Fatal Accidents"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "right"
  ) +
  # Add a legend  
  guides(fill = guide_legend(title = "Metric")) +
  scale_fill_manual(values = "darkgreen", name = "Metric", labels = "Fatal Accidents")

# Print the plots
print(rainfall_plot)
print(accidents_plot)
```

```{r message=FALSE, warning=FALSE}
# Set up the plotting area for histograms and QQ plots
par(mfrow = c(2, 2))  # 2 rows, 2 columns

# Histogram for Rainfall Distribution
hist(precipitation_data$Average, 
     main = "Rainfall Distribution", 
     xlab = "Rainfall (mm)")

# Histogram for Accidents Distribution
hist(accidents$Count, 
     main = "Accidents Distribution", 
     xlab = "Number of Road Accidents")

# QQ Plot for Rainfall
qqnorm(precipitation_data$Average, main = "QQ Plot of Rainfall")
qqline(precipitation_data$Average, col = "red")

# QQ Plot for Accidents
qqnorm(accidents$Count, main = "QQ Plot of Accidents")
qqline(accidents$Count, col = "red")

# Reset plotting area
par(mfrow = c(1, 1))
```

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
# Merge by Year and Month
df <- merge(accidents, precip, by = c("Year", "Month"))

# Create Date column
df$Date <- as.Date(paste(df$Year, df$Month, "01", sep = "-"))

# Rename columns for clarity
names(df)[names(df) == "Count"] <- "Accidents"
names(df)[names(df) == "Average"] <- "Rainfall"

# --- 3. Visualize Time Series ---
ggplot(df, aes(x = Date)) +
  geom_line(aes(y = Rainfall, color = "Rainfall")) +
  geom_line(aes(y = Accidents * 20, color = "Road Accidents")) +  # Scaling for clarity
  scale_y_continuous(name = "Rainfall (mm)", sec.axis = sec_axis(~./20, name="Fatal Road Accidents")) +
  labs(
    title = "Monthly Rainfall and Fatal Accidents in Tasmania", 
    x = "Year", 
    color = "Legend"  # This changes "colour" to "Legend"
  ) +
  theme_minimal() +
  scale_color_manual(values = c("Rainfall" = "blue", "Road Accidents" = "red"))

```

# Check Stationarity 

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Load required libraries
library(knitr)
library(tseries)  # Make sure this is loaded for adf.test function

# Perform ADF tests and store results
# Make sure precip$Average and accidents$Count exist and are numeric
rainfall_adf <- adf.test(precip$Average, alternative = "stationary") 
accident_adf <- adf.test(accidents$Count, alternative = "stationary")

# Extract relevant information
# Handle p-values properly when they're very small
rainfall_p <- if(rainfall_adf$p.value < 0.01) "< 0.01" else as.character(round(rainfall_adf$p.value, 4))
accident_p <- if(accident_adf$p.value < 0.01) "< 0.01" else as.character(round(accident_adf$p.value, 4))

# Extract statistics and convert to numeric for proper rounding
rainfall_stat <- as.numeric(rainfall_adf$statistic)
accident_stat <- as.numeric(accident_adf$statistic)

# Extract lag order
rainfall_lag <- rainfall_adf$parameter["lag order"]
accident_lag <- accident_adf$parameter["lag order"]

# Create a data frame to store the results
adf_results <- data.frame(
  Variable = c("Rainfall Average", "Accident Count"),
  "Dickey-Fuller Statistic" = c(round(rainfall_stat, 4), round(accident_stat, 4)),
  "p-value" = c(rainfall_p, accident_p),
  "Alternative Hypothesis" = c("stationary", "stationary"),
  stringsAsFactors = FALSE
)

# Simple kable output
kable(adf_results, caption = "Augmented Dickey-Fuller Test Results", align = c('l', 'r', 'r', 'r', 'l'))

```

# Threshold Selection

## Mean Residual Life Plot an Stability Plot**

**1. Rainfall**

```{r echo=FALSE, message=FALSE, warning=FALSE}
# For Rainfall
mrlplot(df$Rainfall)
```

**2. Road Accident**

```{r echo=FALSE, message=FALSE, warning=FALSE}
# For Accidents
mrlplot(df$Accidents)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Load required package
library(evd)

# Define thresholds to test (quantiles)
threshold_probs <- c(0.50,0.60,0.80,0.85,0.90,0.95,0.99)

# Initialize storage for Rainfall
rain_shape <- numeric(length(threshold_probs))
rain_scale <- numeric(length(threshold_probs))
rain_nexc <- numeric(length(threshold_probs))

# Initialize storage for Accidents
acc_shape <- numeric(length(threshold_probs))
acc_scale <- numeric(length(threshold_probs))
acc_nexc <- numeric(length(threshold_probs))

# Loop over thresholds
for (i in seq_along(threshold_probs)) {
  # Rainfall GPD fit
  rain_u <- quantile(df$Rainfall, threshold_probs[i])
  rain_fit <- gpd.fit(df$Rainfall, threshold = rain_u)
  rain_shape[i] <- rain_fit$mle[2]  # Shape
  rain_scale[i] <- rain_fit$mle[1]  # Scale
  rain_nexc[i] <- rain_fit$nexc     # Number of exceedances
  
  # Accidents GPD fit
  acc_u <- quantile(df$Accidents, threshold_probs[i])
  acc_fit <- gpd.fit(df$Accidents, threshold = acc_u)
  acc_shape[i] <- acc_fit$mle[2]
  acc_scale[i] <- acc_fit$mle[1]
  acc_nexc[i] <- acc_fit$nexc
}
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
# -------------------- Plotting --------------------
# Set layout: 2 rows x 2 columns
par(mfrow = c(2, 2))

# --- Rainfall plots ---
# Shape Parameter
plot(threshold_probs, rain_shape, type = "b", pch = 19, col = "darkblue",
     xlab = "Threshold Quantile", ylab = "Shape Parameter (ξ)",
     main = "Shape Parameter vs Threshold (Rainfall)")
abline(h = 0, col = "gray", lty = 2)

# Number of Exceedances
plot(threshold_probs, rain_nexc, type = "b", pch = 19, col = "darkgreen",
     xlab = "Threshold Quantile", ylab = "Number of Exceedances",
     main = "Exceedances vs Threshold (Rainfall)")

# --- Accidents plots ---
# Shape Parameter
plot(threshold_probs, acc_shape, type = "b", pch = 19, col = "darkblue",
     xlab = "Threshold Quantile", ylab = "Shape Parameter (ξ)",
     main = "Shape Parameter vs Threshold (Accidents)")
abline(h = 0, col = "gray", lty = 2)

# Number of Exceedances
plot(threshold_probs, acc_nexc, type = "b", pch = 19, col = "darkgreen",
     xlab = "Threshold Quantile", ylab = "Number of Exceedances",
     main = "Exceedances vs Threshold (Accidents)")

# Load required package
library(knitr)

# Create a summary data frame
summary_table <- data.frame(
  Rain_Thresh = quantile(df$Rainfall, threshold_probs),
  R_Shape     = round(rain_shape, 4),
  R_Scale     = round(rain_scale, 4),
  R_Exceedances = rain_nexc,
  
  Acc_Thresh = quantile(df$Accidents, threshold_probs),
  A_Shape     = round(acc_shape, 4),
  A_Scale     = round(acc_scale, 4),
  A_Exceedances = acc_nexc
)

# Filter for threshold quantiles 0.80 to 0.99
#filtered_summary <- summary_table[summary_table$Threshold_Quantile >= 0.80, ]

# Display using kable
kable(summary_table, caption = "GPD Fit Summary for Rainfall and Accidents (Thresholds: 50%–99%)")
```


# Marginal Threshold Selection & Modeling

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Load required packages
library(knitr)
library(dplyr)
library(ggplot2)
library(extRemes)
# ============================================================================
# 1. Set Thresholds and Fit Marginal GPD Models
# ============================================================================
# Set thresholds at the 85th percentile
percentile <- 0.85
rain_threshold <- quantile(df$Rainfall, percentile) 
acc_threshold <- quantile(df$Accidents, percentile)  

# Create a thresholds summary table with percentile
thresholds_table <- data.frame(
  Variable = c("Rainfall", "Accidents"),
  Percentile = paste0(percentile * 100, "th"),
  Threshold = c(rain_threshold, acc_threshold)
)

# Display table using kable
kable(thresholds_table, caption = "Selected Thresholds at the 85th Percentile")
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
# Load required packages
library(evd)
library(ggplot2)
library(gridExtra)

# Extract exceedances
exceed_rain <- df$Rainfall[df$Rainfall > rain_threshold] - rain_threshold
exceed_acc <- df$Accidents[df$Accidents > acc_threshold] - acc_threshold

# Fit GPD
fit_rain <- fpot(df$Rainfall, threshold = rain_threshold)
fit_acc <- fpot(df$Accidents, threshold = acc_threshold)

# Rainfall
fevd_rain <- fevd(df$Rainfall, threshold = rain_threshold, type = "GP", method = "MLE")
# Accidents
fevd_acc <- fevd(df$Accidents, threshold = acc_threshold, type = "GP", method = "MLE")

# Rainfall plots with custom titles
plot(fevd_rain, "qq", main = "QQ-Plot for Rainfall")
plot(fevd_rain, "density", main = "Density Plot for Rainfall")

# Accidents plots with custom titles
plot(fevd_acc, "qq", main = "QQ-Plot for Road Accidents")
plot(fevd_acc, "density", main = "Density Plot for Road Accidents")

# Set a larger figure size with more height
dev.new(width = 10, height = 8)  # Increase these values for larger plots

# Arrange plots in a 2x2 grid with custom titles
par(mfrow = c(2, 2), mar = c(4.5, 4.5, 3, 2))  # Adjust margins for better spacing

# Rainfall plots with custom titles
plot(fevd_rain, "qq", main = "QQ-Plot for Rainfall")
plot(fevd_rain, "density", main = "Density Plot for Rainfall")

# Accidents plots with custom titles
plot(fevd_acc, "qq", main = "QQ-Plot for Road Accidents")
plot(fevd_acc, "density", main = "Density Plot for Road Accidents")
```



```{r include=FALSE}
# Fit GPD to rainfall exceedances
fit_rain <- gpd.fit(df$Rainfall, threshold = rain_threshold)

# Fit GPD to accident exceedances
fit_accidents <- gpd.fit(df$Accidents, threshold = acc_threshold)
```

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# ============================================================================
# 2. Extract and Transform Joint Exceedances to Uniform Margins
# ============================================================================
library(evd)
# Find observations that exceed both thresholds
co_exceed_idx <- which(df$Rainfall > rain_threshold & df$Accidents > acc_threshold)

# Transform to uniform margins using fitted GPD
u_rain <- pgpd(df$Rainfall[co_exceed_idx], 
              loc = fit_rain$threshold, 
              scale = fit_rain$mle[1], 
              shape = fit_rain$mle[2])

u_acc <- pgpd(df$Accidents[co_exceed_idx], 
             loc = fit_accidents$threshold, 
             scale = fit_accidents$mle[1], 
             shape = fit_accidents$mle[2])
```

```{r echo=FALSE}
# Find observations that exceed both thresholds
co_exceed_idx <- which(df$Rainfall > rain_threshold & df$Accidents > acc_threshold)

# The pgpd() function in the evd package uses different parameter names
# It doesn't have a 'loc' parameter - instead, the threshold is already factored out

# For rainfall exceedances - transform to uniform margins
rain_exceedances <- df$Rainfall[co_exceed_idx] - rain_threshold
u_rain <- pgpd(rain_exceedances, 
              scale = fit_rain$mle[1], 
              shape = fit_rain$mle[2])

# For accident exceedances - transform to uniform margins  
acc_exceedances <- df$Accidents[co_exceed_idx] - acc_threshold
u_acc <- pgpd(acc_exceedances, 
             scale = fit_accidents$mle[1], 
             shape = fit_accidents$mle[2])

# Combine into a single dataset
u_data <- cbind(u_rain, u_acc)

# Check dependence using rank correlation
#cor.test(u_rain, u_acc, method = "kendall")
#cor.test(u_rain, u_acc, method = "spearman")

# Suppress warnings and extract correlation results
kendall_res <- suppressWarnings(cor.test(u_rain, u_acc, method = "kendall"))
spearman_res <- suppressWarnings(cor.test(u_rain, u_acc, method = "spearman"))

# Create a summary table
cor_results <- data.frame(
  Method = c("Kendall", "Spearman"),
  Estimate = c(round(kendall_res$estimate, 4), round(spearman_res$estimate, 4)),
  `p-value` = c(round(kendall_res$p.value, 4), round(spearman_res$p.value, 4)),
  stringsAsFactors = FALSE
)

# Display with kable
knitr::kable(cor_results, caption = "Kendall and Spearman Tests for Dependence in Joint Exceedances")

```

```{r}
# Create a scatter plot of pseudo-observations (uniform transformations)
# Place this after you've created the u_rain and u_acc variables

# Basic scatter plot of pseudo-observations
ggplot(data.frame(u_rain = u_rain, u_acc = u_acc), aes(x = u_rain, y = u_acc)) +
  geom_point(size = 2.5, alpha = 0.7, color = "darkblue") +
  labs(title = "Scatter Plot of Pseudo-Observations",
       subtitle = "Uniform transformations of joint exceedances",
       x = "Transformed Rainfall", 
       y = "Transformed Road Accident") +
  theme_minimal() +
  # Add grid lines for reference
  geom_hline(yintercept = seq(0, 1, by = 0.2), linetype = "dashed", color = "gray90") +
  geom_vline(xintercept = seq(0, 1, by = 0.2), linetype = "dashed", color = "gray90") +
  # Add diagonal reference line
  geom_abline(intercept = 0, slope = 1, linetype = "dotted", color = "red") +
  # Ensure square aspect ratio
  coord_fixed() +
  # Set axis limits
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.2)) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.2))
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
# Plot
# Classify data points
df$Type <- "Non-Exceedance"
df$Type[df$Rainfall > rain_threshold & df$Accidents > acc_threshold] <- "Joint Exceedance"
df$Type[df$Rainfall > rain_threshold & df$Accidents <= acc_threshold] <- "Rain Only"
df$Type[df$Rainfall <= rain_threshold & df$Accidents > acc_threshold] <- "Accident Only"

# Plot
library(ggplot2)
ggplot(df, aes(x = Rainfall, y = Accidents, color = Type)) +
  geom_point(size = 2, alpha = 0.7) +
  geom_vline(xintercept = rain_threshold, linetype = "dashed", color = "blue") +
  geom_hline(yintercept = acc_threshold, linetype = "dashed", color = "red") +
  scale_color_manual(values = c("lightblue", "black", "darkgrey", "lightpink")) +
  labs(title = "Joint and Marginal Exceedances of Rainfall and Road Accident",
       x = "Rainfall", y = "Road Accident") +
  theme_minimal()

```

# Fitting Copula

```{r message=FALSE, warning=FALSE}
# ============================================================================
# 3. Fit Multiple Copulas to the Joint Distribution
# ============================================================================

# Define different copulas
copulas <- list(
  gumbel = gumbelCopula(dim = 2),
  clayton = claytonCopula(dim = 2),
  frank = frankCopula(dim = 2),
  gaussian = normalCopula(dim = 2)
)

# Fit each copula using maximum likelihood
fits <- list()
for (name in names(copulas)) {
  fits[[name]] <- fitCopula(copulas[[name]], u_data, method = "ml")
  cat("Fitted", name, "copula. Log-likelihood:", logLik(fits[[name]]), "\n")
}

# ============================================================================
# 4. Generate Contour Plots for Each Fitted Copula
# ============================================================================

# Create grid for density evaluation
u_seq <- seq(0, 1, length.out = 100)
cop_grid <- as.matrix(expand.grid(u_seq, u_seq))
colnames(cop_grid) <- c("u1", "u2")
options(repr.plot.width = 10, repr.plot.height = 10)
# Set up 2x2 plot layout
par(mfrow = c(2, 2))

# Plot contours for each copula
for (name in names(fits)) {
  # Evaluate copula density
  z <- dCopula(cop_grid, copula = fits[[name]]@copula)
  z_matrix <- matrix(z, nrow = 100, ncol = 100)
  
  # Plot contour with data points
  contour(u_seq, u_seq, z_matrix,
         xlab = "Transformed Rainfall",
         ylab = "Transformed Road Accident",
         main = paste(name, "Copula Contours"))
  points(u_data, pch = 19, col = rgb(0, 0, 1, 0.5))
}

par(mfrow = c(1, 1))
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
# ============================================================================
# 5. Model Selection and Goodness-of-Fit
# ============================================================================

# Compare AIC values
aic_values <- sapply(fits, function(fit) {
  logL <- logLik(fit)
  k <- length(coef(fit))
  -2 * as.numeric(logL) + 2 * k
})

# Create results table
results <- data.frame(
  Copula = names(fits),
  LogLik = sapply(fits, function(x) as.numeric(logLik(x))),
  Parameter = sapply(fits, function(x) coef(x)),
  AIC = round(aic_values, 4)
)

print(results)

# ============================================================================
# 6. Cramér-von Mises Goodness-of-Fit Test
# ============================================================================

# Function to compute Cramér-von Mises statistic
compute_cvm <- function(copula_fit, data) {
  n <- nrow(data)
  
  # Transform data using Rosenblatt transformation
  U <- cCopula(data, copula_fit@copula, inverse = FALSE)
  
  # For the first margin, we just use U[,1]
  # For the second margin, we compute C_{2|1}(u2|u1) 
  
  # Compute empirical distribution function
  S_n <- function(t1, t2) {
    mean(U[,1] <= t1 & U[,2] <= t2)
  }
  
  # Compute theoretical distribution function (which is just the product for independence)
  C_theta <- function(t1, t2) {
    t1 * t2  # For transformed data, this should be uniform [0,1]
  }
  
  # Compute CvM statistic (approximate using grid)
  grid_points <- 20
  t1_grid <- seq(0, 1, length.out = grid_points)
  t2_grid <- seq(0, 1, length.out = grid_points)
  
  cvm_sum <- 0
  for (t1 in t1_grid) {
    for (t2 in t2_grid) {
      diff <- S_n(t1, t2) - C_theta(t1, t2)
      cvm_sum <- cvm_sum + diff^2
    }
  }
  
  # Normalize by grid size
  cvm_stat <- cvm_sum / (grid_points^2)
  return(cvm_stat)
}

# Alternative: Use gofCopula from copula package for more accurate tests
cvm_results <- list()
p_values <- list()

for (name in names(copulas)) {
  # Use appropriate estimation methods for each copula
  est_method <- if(name %in% c("gumbel", "clayton", "frank")) "itau" else "ml"
  
  # Run GOF test (may need to adjust N.bootstrap if running into issues)
  tryCatch({
    gof_test <- gofCopula(
      copula = copulas[[name]],
      x = u_data,
      method = "Sn",           # Cramér-von Mises statistic
      estim.method = est_method,
      simulation = "pb",       # Parametric bootstrap
      N = 10000                 # Number of bootstrap replications
    )
    
    cvm_results[[name]] <- gof_test$statistic
    p_values[[name]] <- gof_test$p.value
    
    cat("Cramer-von Mises test for", name, "copula:\n")
    cat("  Statistic:", gof_test$statistic, "\n")
    cat("  p-value:", gof_test$p.value, "\n\n")
  }, error = function(e) {
    cat("Error in gofCopula for", name, "copula:", e$message, "\n")
    # Fall back to custom implementation if official function fails
    cvm_stat <- compute_cvm(fits[[name]], u_data)
    cvm_results[[name]] <- cvm_stat
    p_values[[name]] <- NA
    cat("  Custom CvM statistic:", cvm_stat, "\n\n")
  })
}

# Combine GOF results
gof_summary <- data.frame(
  Copula = names(copulas),
  CvM_Statistic = unlist(cvm_results),
  p_value = unlist(p_values)
)

# Print comprehensive comparison table
final_results <- merge(results, gof_summary, by = "Copula")
print(final_results)

```

## **Goodness-of-Fit Test**

```{r message=FALSE, warning=FALSE}
# ============================================================================
# 7. Displaying Results with kable
# ============================================================================

# Load the knitr package if not already loaded
if (!require("knitr")) {
  install.packages("knitr")
  library(knitr)
}

# Format the final results table using kable
kable_table <- kable(final_results, 
      caption = "Comparison of Copula Models", 
      format = "latex", 
      digits = 4,
      col.names = c("Copula", "Log-Likelihood", "Parameter", "AIC", 
                    "CvM Statistic", "p-value"),
      align = c('l', 'r', 'r', 'r', 'r', 'r'))

# Add some styling with kableExtra (optional)
if (require("kableExtra")) {
  kable_table <- kable_table %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                  full_width = FALSE) %>%
    row_spec(which.min(final_results$AIC), bold = TRUE, 
             background = "#E8F4F8") %>%
    add_header_above(c(" " = 1, "Model Fit" = 3, "Goodness-of-Fit" = 2))
}


# ============================================================================
# 7. Q-Q Plots for Copula Goodness-of-Fit
# ============================================================================

# Estimation methods for GOF testing
estimation_methods <- list(
  gumbel = "itau",
  clayton = "itau",
  frank = "itau",
  gaussian = "itau"
)
# Set up 2x2 plot layout
par(mfrow = c(2, 2))

# Create Q-Q plots for each copula
for (name in names(copulas)) {
  # Fit copula using rank correlation (more robust with small samples)
  cop <- copulas[[name]]
  est_method <- estimation_methods[[name]]
  fit <- fitCopula(cop, u_data, method = est_method)
  fitted_copula <- fit@copula
  
  # Generate sample from fitted copula
  set.seed(123)
  n_sim <- 10000  # Use a large number for smoother empirical CDF
  sim_data <- rCopula(n_sim, fitted_copula)
  
  # Compute Rosenblatt's transform (probability integral transform)
  # For bivariate case:
  # T1 = u1
  # T2 = C2|1(u2|u1)
  
  # For observed data
  T1_obs <- u_data[,1]
  T2_obs <- cCopula(u_data, fitted_copula, inverse = FALSE)[,2]
  
  # For simulated data
  T1_sim <- sim_data[,1]
  T2_sim <- cCopula(sim_data, fitted_copula, inverse = FALSE)[,2]
  
  # Q-Q plot
  quantiles_obs <- quantile(T2_obs, probs = seq(0, 1, 0.1))
  quantiles_sim <- quantile(T2_sim, probs = seq(0, 1, 0.1))
  
  plot(quantiles_sim, quantiles_obs,
       main = paste("Q-Q Plot:", name, "copula"),
       xlab = "Theoretical Quantiles", 
       ylab = "Sample Quantiles",
       pch = 19, col = "blue")
  abline(0, 1, col = "red", lty = 2)
}

par(mfrow = c(1, 1))

# Print the formatted table
kable_table
```


```{r}
# Estimation methods for GOF testing
estimation_methods <- list(
  gumbel = "itau",
  clayton = "itau",
  frank = "itau",
  gaussian = "itau"
)

# Adjust the figure size before plotting
# This opens a new device with specific dimensions
# Adjust the height to be larger (e.g., 10 inches tall instead of 7)
dev.new(width = 10, height = 12)  # Make the plots taller

# Set up 2x2 plot layout with custom spacing
layout(matrix(1:4, nrow = 2, byrow = TRUE))
par(mar = c(5, 5, 4, 2) + 0.1)  # Increase margins

# Create Q-Q plots for each copula
for (name in names(copulas)) {
  # Fit copula using rank correlation (more robust with small samples)
  cop <- copulas[[name]]
  est_method <- estimation_methods[[name]]
  fit <- fitCopula(cop, u_data, method = est_method)
  fitted_copula <- fit@copula
  
  # Generate sample from fitted copula
  set.seed(123)
  n_sim <- 10000  # Use a large number for smoother empirical CDF
  sim_data <- rCopula(n_sim, fitted_copula)
  
  # Compute Rosenblatt's transform
  T1_obs <- u_data[,1]
  T2_obs <- cCopula(u_data, fitted_copula, inverse = FALSE)[,2]
  T1_sim <- sim_data[,1]
  T2_sim <- cCopula(sim_data, fitted_copula, inverse = FALSE)[,2]
  
  # Q-Q plot
  quantiles_obs <- quantile(T2_obs, probs = seq(0, 1, 0.1))
  quantiles_sim <- quantile(T2_sim, probs = seq(0, 1, 0.1))
  
  plot(quantiles_sim, quantiles_obs,
       main = paste("Q-Q Plot:", name, "copula"),
       xlab = "Theoretical Quantiles", 
       ylab = "Sample Quantiles",
       pch = 19, col = "blue",
       cex.main = 1.3,  # Larger title text
       cex.lab = 1.2,   # Larger axis labels
       cex.axis = 1.1,  # Larger axis numbers
       xlim = c(0, 1),
       ylim = c(0, 1))
  abline(0, 1, col = "red", lty = 2)
}

# Reset to default layout
layout(1)
```



```{r}
# ============================================================================
# 8. Generate Scatter Plots of Simulated Data from Best-Fitting Copula
# ============================================================================

# Identify the best copula based on AIC
best_copula_name <- names(fits)[which.min(aic_values)]
best_fit <- fits[[best_copula_name]]
best_fitted_copula <- best_fit@copula

# Set seed for reproducibility
set.seed(123)

# Generate simulated data from the best-fitting copula
n_sim <- 100  # Number of simulated points - adjust as needed
sim_data <- rCopula(n_sim, best_fitted_copula)

# Create a plot comparing observed and simulated data
# Multiply the simulated points to make the pattern clearer
par(mfrow = c(1, 2))

# Plot 1: Observed data
plot(u_data, 
     main = "Observed Pseudo-Observations",
     xlab = "Transformed Rainfall", 
     ylab = "Transformed Accidents",
     pch = 19, col = "darkblue", 
     xlim = c(0, 1), ylim = c(0, 1))
abline(0, 1, lty = 2, col = "red")

# Plot 2: Simulated data from best-fitting copula
plot(sim_data, 
     main = paste("Simulated Data from", best_copula_name, "Copula"),
     xlab = "Simulated Rainfall", 
     ylab = "Simulated Accidents",
     pch = 19, col = "darkgreen", 
     xlim = c(0, 1), ylim = c(0, 1))
abline(0, 1, lty = 2, col = "red")

par(mfrow = c(1, 1))

# Alternative: Create a more sophisticated visualization with ggplot2
if (require("ggplot2") && require("gridExtra")) {
  # Prepare observed data
  obs_df <- data.frame(
    x = u_data[,1],
    y = u_data[,2],
    type = "Observed"
  )
  
  # Prepare simulated data
  sim_df <- data.frame(
    x = sim_data[,1],
    y = sim_data[,2],
    type = "Simulated"
  )
  
  # Combine data
  combined_df <- rbind(obs_df, sim_df)
  
  # Create a side-by-side comparison plot
  p <- ggplot(combined_df, aes(x = x, y = y)) +
    geom_point(size = 2, alpha = 0.7, color = "darkblue") +
    geom_abline(intercept = 0, slope = 1, linetype = "dotted", color = "red") +
    facet_wrap(~ type) +
    labs(title = paste("Comparison: Observed vs", best_copula_name, "Copula Simulated Data"),
         x = "Transformed Rainfall", 
         y = "Transformed Road Accident") +
    theme_minimal() +
    coord_fixed() +
    scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.2)) +
    scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.2)) +
    geom_hline(yintercept = seq(0, 1, by = 0.2), linetype = "dashed", color = "gray90") +
    geom_vline(xintercept = seq(0, 1, by = 0.2), linetype = "dashed", color = "gray90")
  
  print(p)
}

# ============================================================================
# 8. Generate Scatter Plots of Simulated Data from Best-Fitting Copula
# ============================================================================

best_copula_name <- "frank"
best_fit <- fits[[best_copula_name]]
best_fitted_copula <- best_fit@copula

best_copula_name <- "frank"
best_copula_fit <- fits[[best_copula_name]]

# Set seed for reproducibility
set.seed(123)

# Generate simulated data from the best-fitting copula
n_sim <- 100  # Number of simulated points - adjust as needed
sim_data <- rCopula(n_sim, best_fitted_copula)

# Create a plot comparing observed and simulated data
# Multiply the simulated points to make the pattern clearer
par(mfrow = c(1, 2))

# Plot 1: Observed data
plot(u_data, 
     main = "Observed Pseudo-Observations",
     xlab = "Transformed Rainfall", 
     ylab = "Transformed Accidents",
     pch = 19, col = "darkblue", 
     xlim = c(0, 1), ylim = c(0, 1))
abline(0, 1, lty = 2, col = "red")

# Plot 2: Simulated data from best-fitting copula
plot(sim_data, 
     main = paste("Simulated Data from", best_copula_name, "Copula"),
     xlab = "Simulated Rainfall", 
     ylab = "Simulated Accidents",
     pch = 19, col = "darkgreen", 
     xlim = c(0, 1), ylim = c(0, 1))
abline(0, 1, lty = 2, col = "red")

par(mfrow = c(1, 1))
```

```{r echo=FALSE}
# Alternative: Create a more sophisticated visualization with ggplot2
if (require("ggplot2") && require("gridExtra")) {
  # Prepare observed data
  obs_df <- data.frame(
    x = u_data[,1],
    y = u_data[,2],
    type = "Observed"
  )
  
  # Prepare simulated data
  sim_df <- data.frame(
    x = sim_data[,1],
    y = sim_data[,2],
    type = "Simulated"
  )
  
  # Combine data
  combined_df <- rbind(obs_df, sim_df)
  
  # Create a side-by-side comparison plot
  p <- ggplot(combined_df, aes(x = x, y = y)) +
    geom_point(size = 2, alpha = 0.7, color = "darkblue") +
    geom_abline(intercept = 0, slope = 1, linetype = "dotted", color = "red") +
    facet_wrap(~ type) +
    labs(title = paste("Comparison: Observed vs", best_copula_name, "Copula Simulated Data"),
         x = "Transformed Rainfall", 
         y = "Transformed Accidents") +
    theme_minimal() +
    coord_fixed() +
    scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.2)) +
    scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.2)) +
    geom_hline(yintercept = seq(0, 1, by = 0.2), linetype = "dashed", color = "gray90") +
    geom_vline(xintercept = seq(0, 1, by = 0.2), linetype = "dashed", color = "gray90")
  
  print(p)
}
```
# Joint Return Period

**Frank Copula**

```{R message=FALSE, warning=FALSE}
# ============================================================================
# 8. Joint Return Period Analysis Using Frank Copula (Fixed Version)
# ============================================================================
library(knitr)
library(ggplot2)
library(gridExtra)
library(viridis)
library(evd)  # Make sure this is loaded explicitly
library(dplyr) # Added for pipe operations and data manipulation

# Select the best copula model (Frank based on the analysis results)
best_copula <- fits[["frank"]]@copula

# Extract parameters from fitted marginal GPD models
rain_scale <- fit_rain$mle[1]      # Scale parameter for rainfall
rain_shape <- fit_rain$mle[2]      # Shape parameter for rainfall
rain_rate <- fit_rain$rate         # Rate of exceedances for rainfall

acc_scale <- fit_accidents$mle[1]  # Scale parameter for accidents
acc_shape <- fit_accidents$mle[2]  # Shape parameter for accidents
acc_rate <- fit_accidents$rate     # Rate of exceedances for accidents

# Define thresholds
u_rain_threshold <- rain_threshold
u_acc_threshold <- acc_threshold

# Number of observations per year (monthly data)
n_per_year <- 12  # Monthly data: 12 observations per year

# Define return periods to calculate (in years)
return_periods <- c(5, 10, 20, 50, 100)

# Function to compute rainfall level for a given return period
get_rainfall_level <- function(return_period) {
  p <- 1 - 1/(return_period * n_per_year)
  if(rain_shape == 0) {
    return(u_rain_threshold + rain_scale * log(1/rain_rate * (1-p)))
  } else {
    return(u_rain_threshold + (rain_scale/rain_shape) * 
             ((rain_rate/(1-p))^rain_shape - 1))
  }
}

# Function to compute accident level for a given return period
get_accident_level <- function(return_period) {
  p <- 1 - 1/(return_period * n_per_year)
  if(acc_shape == 0) {
    return(u_acc_threshold + acc_scale * log(1/acc_rate * (1-p)))
  } else {
    return(u_acc_threshold + (acc_scale/acc_shape) * ((acc_rate/(1-p))^acc_shape - 1))
  }
}

# ============================================================================
# 8.1 Calculate Joint Return Periods for "AND" Case
# ============================================================================

# The "AND" case corresponds to P(X > x AND Y > y)
# Return period = 1 / P(X > x AND Y > y)

# Create result table
joint_and_results <- data.frame(
  ReturnPeriod = return_periods,
  RainfallLevel = numeric(length(return_periods)),
  AccidentLevel = numeric(length(return_periods)),
  Probability = numeric(length(return_periods)),
  JointReturnPeriod = numeric(length(return_periods))
)

# For each return period, calculate the corresponding levels and joint probability
for(i in 1:length(return_periods)) {
  # Get marginal return levels
  rp <- return_periods[i]
  rainfall_level <- get_rainfall_level(rp)
  accident_level <- get_accident_level(rp)
  
  # Transform to uniform margins
  # FIXED: In evd package pgpd() doesn't use 'loc' parameter - threshold has already been accounted for
  # in the calculation of exceedances
  u_rainfall <- 1 - rain_rate * (1 - pgpd(rainfall_level - rain_threshold, 
                                         scale = rain_scale, 
                                         shape = rain_shape))
  
  u_accident <- 1 - acc_rate * (1 - pgpd(accident_level - acc_threshold, 
                                        scale = acc_scale, 
                                        shape = acc_shape))
  
  # Calculate joint probability using copula
  joint_prob_and <- 1 - u_rainfall - u_accident + pCopula(c(u_rainfall, 
                                                            u_accident), 
                                                          best_copula)
  joint_return_and <- 1 / (joint_prob_and / n_per_year)
  
  # Store results
  joint_and_results$RainfallLevel[i] <- rainfall_level
  joint_and_results$AccidentLevel[i] <- accident_level
  joint_and_results$Probability[i] <- joint_prob_and
  joint_and_results$JointReturnPeriod[i] <- joint_return_and
}

# Format the results table
kable(joint_and_results, 
      caption = "Joint Return Periods for Rainfall AND Accidents",
      digits = c(0, 2, 2, 6, 2))

# ============================================================================
# 8.2 Calculate Joint Return Periods for "OR" Case
# ============================================================================

# The "OR" case corresponds to P(X > x OR Y > y)
# Return period = 1 / P(X > x OR Y > y)

# Create result table
joint_or_results <- data.frame(
  ReturnPeriod = return_periods,
  RainfallLevel = numeric(length(return_periods)),
  AccidentLevel = numeric(length(return_periods)),
  Probability = numeric(length(return_periods)),
  JointReturnPeriod = numeric(length(return_periods))
)

# For each return period, calculate the corresponding levels and joint probability
for(i in 1:length(return_periods)) {
  # Get marginal return levels
  rp <- return_periods[i]
  rainfall_level <- get_rainfall_level(rp)
  accident_level <- get_accident_level(rp)
  
  # Transform to uniform margins
  u_rainfall <- 1 - rain_rate * (1 - pgpd(rainfall_level - rain_threshold, 
                                         scale = rain_scale, 
                                         shape = rain_shape))
  
  u_accident <- 1 - acc_rate * (1 - pgpd(accident_level - acc_threshold, 
                                        scale = acc_scale, 
                                        shape = acc_shape))
  
  # Calculate joint probability using copula (OR case)
  # FIXED: The correct formula for P(X > x OR Y > y) is:
  # P(X > x OR Y > y) = (1 - F_X(x)) + (1 - F_Y(y)) - P(X > x AND Y > y)
  # Where F_X and F_Y are the cumulative distribution functions
  # In terms of our uniform margins u_rainfall and u_accident:
  # P(X > x OR Y > y) = (1 - u_rainfall) + (1 - u_accident) - P(X > x AND Y > y)
  
  # First calculate P(X > x AND Y > y) as we did earlier
  joint_prob_and_i <- 1 - u_rainfall - u_accident + pCopula(c(u_rainfall, 
                                                              u_accident), 
                                                            best_copula)
  
  # Now calculate P(X > x OR Y > y)
  joint_prob_or <- (1 - u_rainfall) + (1 - u_accident) - joint_prob_and_i
  joint_return_or <- 1 / (joint_prob_or / n_per_year)
  
  # Store results
  joint_or_results$RainfallLevel[i] <- rainfall_level
  joint_or_results$AccidentLevel[i] <- accident_level
  joint_or_results$Probability[i] <- joint_prob_or
  joint_or_results$JointReturnPeriod[i] <- joint_return_or
}

# Format the results table
kable(joint_or_results, 
      caption = "Joint Return Periods for Rainfall OR Accidents",
      digits = c(0, 2, 2, 6, 2))

# ============================================================================
# 8.3 Display Results Using kable
# ============================================================================

# Create a combined table for AND and OR cases
combined_results <- data.frame(
  ReturnPeriod = return_periods,
  RainfallLevel = round(joint_and_results$RainfallLevel, 2),
  AccidentLevel = round(joint_and_results$AccidentLevel, 2),
  AND_Probability = round(joint_and_results$Probability, 6),
  AND_JointReturnPeriod = round(joint_and_results$JointReturnPeriod, 2),
  OR_Probability = round(joint_or_results$Probability, 6),
  OR_JointReturnPeriod = round(joint_or_results$JointReturnPeriod, 2)
)


# ============================================================================
# 9. Improved Visualization of Joint Return Periods
# ============================================================================

# Create a grid of points for the contour plot
grid_size <- 100
x_grid <- seq(min(df$Rainfall), max(df$Rainfall) * 1.5, length.out = grid_size)
y_grid <- seq(min(df$Accidents), max(df$Accidents) * 1.5, length.out = grid_size)
xy_grid <- expand.grid(Rainfall = x_grid, Accidents = y_grid)

# Transform to uniform margins
u_grid <- matrix(NA, nrow = nrow(xy_grid), ncol = 2)
for(i in 1:nrow(xy_grid)) {
  # For rainfall
  if(xy_grid[i,1] <= rain_threshold) {
    u_grid[i,1] <- (1 - rain_rate) * ecdf(df$Rainfall[df$Rainfall <= rain_threshold])(xy_grid[i,1])
  } else {
    # FIXED: Consistent use of threshold adjustment
    u_grid[i,1] <- 1 - rain_rate * (1 - pgpd(xy_grid[i,1] - rain_threshold, 
                                             scale = rain_scale, shape = rain_shape))
  }
  
  # For accidents
  if(xy_grid[i,2] <= acc_threshold) {
    u_grid[i,2] <- (1 - acc_rate) * ecdf(df$Accidents[df$Accidents <= acc_threshold])(xy_grid[i,2])
  } else {
    # FIXED: Consistent use of threshold adjustment
    u_grid[i,2] <- 1 - acc_rate * (1 - pgpd(xy_grid[i,2] - acc_threshold, 
                                            scale = acc_scale, shape = acc_shape))
  }
}

# Calculate joint probabilities for AND case
joint_probs_and <- 1 - u_grid[,1] - u_grid[,2] + pCopula(u_grid, best_copula)
joint_return_and_grid <- 1 / (joint_probs_and / n_per_year)

# Calculate joint probabilities for OR case
# FIXED: Use consistent formula for OR case
joint_probs_or <- (1 - u_grid[,1]) + (1 - u_grid[,2]) - joint_probs_and
joint_return_or_grid <- 1 / (joint_probs_or / n_per_year)

# Add return periods to grid data for plotting
xy_grid$ReturnPeriod_AND <- joint_return_and_grid
xy_grid$ReturnPeriod_OR <- joint_return_or_grid

# Prepare data for the actual observations
obs_data <- df[, c("Rainfall", "Accidents")]

# ============================================================================
# 9.1 Use ggplot2 for better visualization
# ============================================================================

# Create plots with ggplot2

# AND case - fixed version
p1 <- ggplot() +
  # First pre-filter the grid data to remove extreme/infinite values
  geom_contour_filled(data = xy_grid %>% 
                       # Filter to keep only finite values within a reasonable range
                       filter(is.finite(ReturnPeriod_AND) & 
                              ReturnPeriod_AND <= 500), # Upper cap at 500 years
                     aes(x = Rainfall, y = Accidents, z = ReturnPeriod_AND),
                     breaks = c(0, 5,  10, 20, 50, 100, 200, 500),
                     alpha = 0.7) +
  # Add data points
  geom_point(data = obs_data, 
             aes(x = Rainfall, y = Accidents),
             size = 1, alpha = 0.5, color = "black") +
  # Add labels and title
  labs(title = "Joint Return Periods (AND Case)",
       subtitle = "P(Rainfall > x AND Accidents > y)",
       x = "Rainfall (mm)",
       y = "Number of Accidents") +
  # Customize the color scale
  scale_fill_viridis_d(name = "Return Period (years)", 
                      direction = -1,
                      guide = guide_legend(reverse = TRUE)) +
  # Add theme
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    legend.position = "right"
  )

# OR case - fixed version with similar improvements as p1
p2_improved <- ggplot() +
  # Add contours with better handling of extreme values
  geom_contour_filled(data = xy_grid %>%
                       # Replace infinite and NA values with maximum
                       mutate(ReturnPeriod_OR = case_when(
                         is.infinite(ReturnPeriod_OR) ~ 500,
                         !is.finite(ReturnPeriod_OR) ~ NA_real_,
                         ReturnPeriod_OR > 500 ~ 500,
                         TRUE ~ ReturnPeriod_OR
                       )),
                     aes(x = Rainfall, y = Accidents, z = ReturnPeriod_OR),
                     breaks = c(0, 5, 10, 20, 50, 100, 200, 500),
                     alpha = 0.9) +
  # Add contour lines for clarity
  geom_contour(data = xy_grid %>%
                mutate(ReturnPeriod_OR = case_when(
                  is.infinite(ReturnPeriod_OR) ~ 500,
                  !is.finite(ReturnPeriod_OR) ~ NA_real_,
                  ReturnPeriod_OR > 500 ~ 500,
                  TRUE ~ ReturnPeriod_OR
                )),
              aes(x = Rainfall, y = Accidents, z = ReturnPeriod_OR),
              breaks = c(5, 10, 20, 50, 100, 200),
              color = "white",
              linewidth = 0.3,
              alpha = 0.6) +
  # Add data points
  geom_point(data = obs_data, 
             aes(x = Rainfall, y = Accidents),
             size = 1, alpha = 0.5, color = "black") +
  # Set appropriate limits to avoid extreme areas
  coord_cartesian(
    xlim = c(min(obs_data$Rainfall), max(obs_data$Rainfall) * 1.1),
    ylim = c(min(obs_data$Accidents), max(obs_data$Accidents) * 1.1)
  ) +
  # Add labels and title
  labs(title = "Joint Return Periods (OR Case)",
       subtitle = "P(Rainfall > x OR Accidents > y)",
       x = "Rainfall (mm)",
       y = "Number of Accidents") +
  # Customize the color scale with better labels
  scale_fill_viridis_d(
    name = "Return Period (years)", 
    direction = -1,
    labels = c("0-5", "5-10", "10-20", "20-50", "50-100", "100-200", "200-500"),
    guide = guide_legend(reverse = TRUE)
  ) +
  # Add theme
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    legend.position = "right",
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "gray95")
  )

# Display both plots side by side
#grid.arrange(p1, p2, ncol = 2)
p1
p2_improved
# Save the plots (optional)
#ggsave("joint_return_periods_and.png", p1, width = 8, height = 6)
#ggsave("joint_return_periods_or.png", p2, width = 8, height = 6)

# ============================================================================
# 9.2 Create an additional plot showing points exceeding specific return periods
# ============================================================================

# Create a color-coded scatter plot of observations showing points exceeding specific return periods
# This helps with interpretation by highlighting which past events exceeded certain return periods

# Calculate joint return periods for each observation
obs_return_periods <- data.frame(
  Rainfall = df$Rainfall,
  Accidents = df$Accidents,
  ReturnPeriod_AND = numeric(nrow(df)),
  ReturnPeriod_OR = numeric(nrow(df))
)

for(i in 1:nrow(df)) {
  # Transform to uniform margins
  if(df$Rainfall[i] <= rain_threshold) {
    u_rain <- (1 - rain_rate) * ecdf(df$Rainfall[df$Rainfall <= rain_threshold])(df$Rainfall[i])
  } else {
    # FIXED: Consistent use of threshold adjustment
    u_rain <- 1 - rain_rate * (1 - pgpd(df$Rainfall[i] - rain_threshold, 
                                        scale = rain_scale, shape = rain_shape))
  }
  
  if(df$Accidents[i] <= acc_threshold) {
    u_acc <- (1 - acc_rate) * ecdf(df$Accidents[df$Accidents <= acc_threshold])(df$Accidents[i])
  } else {
    # FIXED: Consistent use of threshold adjustment
    u_acc <- 1 - acc_rate * (1 - pgpd(df$Accidents[i] - acc_threshold, 
                                      scale = acc_scale, shape = acc_shape))
  }
  
  # Calculate AND probability
  joint_prob_and <- 1 - u_rain - u_acc + pCopula(c(u_rain, u_acc), best_copula)
  obs_return_periods$ReturnPeriod_AND[i] <- 1 / (joint_prob_and / n_per_year)
  
  # Calculate OR probability
  # FIXED: Use consistent formula for OR case
  joint_prob_or <- (1 - u_rain) + (1 - u_acc) - joint_prob_and
  obs_return_periods$ReturnPeriod_OR[i] <- 1 / (joint_prob_or / n_per_year)
}

# Create a function to categorize return periods
categorize_return_period <- function(rp) {
  if(rp < 5) return("< 5 years")
  else if(rp < 10) return("5-10 years")
  else if(rp < 20) return("10-20 years")
  else if(rp < 50) return("20-50 years")
  else if(rp < 100) return("50-100 years")
  else return("> 100 years")
}

# Apply categorization
obs_return_periods$Category_AND <- factor(sapply(obs_return_periods$ReturnPeriod_AND, 
                                                 categorize_return_period),
                                        levels = c("< 5 years", "5-10 years", 
                                                   "10-20 years", 
                                                  "20-50 years", 
                                                  "50-100 years", 
                                                  "> 100 years"))

obs_return_periods$Category_OR <- factor(sapply(obs_return_periods$ReturnPeriod_OR, 
                                                categorize_return_period),
                                       levels = c("< 5 years", "5-10 years", 
                                                  "10-20 years", 
                                                  "20-50 years", 
                                                  "50-100 years", 
                                                  "> 100 years"))

# Create plots showing actual observations with their return periods
p3 <- ggplot(obs_return_periods, aes(x = Rainfall, y = Accidents, 
                                     color = Category_AND)) +
  geom_point(size = 2, alpha = 0.8) +
  scale_color_viridis_d(direction = -1) +
  labs(title = "Observed Events by Joint Return Period (AND Case)",
       subtitle = "Monthly Rainfall and Accident Observations",
       x = "Rainfall (mm)",
       y = "Number of Accidents",
       color = "Return Period") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5)
  )

p4 <- ggplot(obs_return_periods, aes(x = Rainfall, y = Accidents, 
                                     color = Category_OR)) +
  geom_point(size = 2, alpha = 0.8) +
  scale_color_viridis_d(direction = -1) +
  labs(title = "Observed Events by Joint Return Period (OR Case)",
       subtitle = "Monthly Rainfall and Accident Observations",
       x = "Rainfall (mm)",
       y = "Number of Accidents",
       color = "Return Period") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5)
  )

# Display the observation plots
#grid.arrange(p3, p4, ncol = 2)

p3
p4

# Use kable with kableExtra for better formatting
kable(combined_results, 
      caption = "Joint Return Periods for AND/OR Cases",
      col.names = c("Return Period", "Rainfall Level", "Accident Level", 
                    "Probability", "Joint RP", 
                    "Probability", "Joint RP"),
      digits = c(0, 2, 2, 6, 2, 6, 2),
      format = "latex", 
      booktabs = TRUE,
      align = c('r', 'r', 'r', 'r', 'r', 'r', 'r')) %>%
  kable_styling(latex_options = c("striped", 
                                  "scale_down", 
                                  "hold_position"),
                font_size = 9) %>%
  add_header_above(c(" " = 3, "AND Case" = 2, "OR Case" = 2))
```








